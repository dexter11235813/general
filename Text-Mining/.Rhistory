links = links[-c(5,10)]
links
links
links = links[-10]
links
links
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) return(links[i]))
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function()
{
for( i in 1:68)
{
temp = extract_text(links[i])
fileCon = file(paste(generate_url(links[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney()
links
links
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links = links[-c(5,10)]
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) {return(links[i]}))
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function()
{
for( i in 1:68)
{
temp = extract_text(links[i])
fileCon = file(paste(generate_url(links[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney()
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links = links[-c(5,10)]
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) {message(paste(links[i]))})
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function()
{
for( i in 1:68)
{
temp = extract_text(links[i])
fileCon = file(paste(generate_url(links[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney()
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links = links[-c(5,12)]
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) {message(paste(links[i]))})
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function()
{
for( i in 1:68)
{
temp = extract_text(links[i])
fileCon = file(paste(generate_url(links[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney()
links1 = links[1:20]
links2 = links[20:40]
links3 = links[41:66]
length(links)
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links = links[-c(5,12)]
links1 = links[1:20]
links2 = links[20:40]
links3 = links[41:66]
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) {message(paste(links[i]))})
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function(x)
{
for( i in 1:length(x))
{
temp = extract_text(x[i])
fileCon = file(paste(generate_url(x[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney(links2)
get_speech_romney(links3)
get_speech_romney(links1)
library(rvest)
library(stringr)
library(magrittr)
## Extract all the links from the page
page = read_html("http://mittromneycentral.com/speeches/")
links = page %>% html_nodes("#content p + p") %>% html_text()
links = links[-c(5,12)]
links1 = links[1:20]
links2 = links[20:40]
links3 = links[41:66]
#### Extract text ###
generate_url = function(x)
{
temp = unlist(strsplit(x," "))
date = temp[length(temp)]
url = paste(unlist(strsplit(date,"/")),collapse = "")
temp = temp[-c(length(temp), length(temp)-1) ]
temp = gsub("[[:punct:]]","",temp)
temp = paste(tolower(temp),collapse = "-")
temp = gsub("--","-",temp)
# temp = gsub(intToUtf8(8217),"",paste(tolower(temp),collapse = "-"))
# temp = gsub(intToUtf8(8216),"",temp)
# temp = gsub("[.]","",temp)
url = paste(url,"-",sep = "")
url = paste(url,temp,sep = "")
url = gsub("-us-","-u-s-",url)
url
}
extract_text = function(x)
{
temp = tryCatch(read_html(paste("http://mittromneycentral.com/speeches/2012-speeches/",generate_url(x),sep = "")),error = function(e) {message(paste(links[i]))})
temp.text  = temp %>% html_nodes(".entry-content p") %>% html_text()
t = paste(temp.text,collapse = "")
t = gsub("\\(APPLAUSE\\)","",t)
return(t)
}
get_speech_romney = function(x)
{
for( i in 1:length(x))
{
temp = extract_text(x[i])
fileCon = file(paste(generate_url(x[i]),".txt",collapse = ""))
writeLines(temp,fileCon)
close(fileCon)
}
}
get_speech_romney(links2)
get_speech_romney(links3)
get_speech_romney(links1)
library(tm)
library(dplyr)
options(stringsAsFactors = F)
candidates = c("Romney","Obama")
CleanCorpus = function(corpus)
{
corpus.tmp = tm_map(corpus,removePunctuation)
corpus.tm = tm_map(corpus.tmp,stripWhitespace)
corpus.tm = tm_map(corpus.tmp,tolower)
corpus.tm = tm_map(corpus.tmp,removeWords,stopwords("english"))
}
library(tm)
library(dplyr)
options(stringsAsFactors = F)
candidates = c("Romney","Obama")
pathname = "\home\abhijit331/Text-Mining/"
# Clean the text
CleanCorpus = function(corpus)
{
corpus.tmp = tm_map(corpus,removePunctuation)
corpus.tm = tm_map(corpus.tmp,stripWhitespace)
corpus.tm = tm_map(corpus.tmp,tolower)
corpus.tm = tm_map(corpus.tmp,removeWords,stopwords("english"))
return(corpus.tm)
}
generateTDM = function(cand,path){
s.dir = sprintf("%s,%s",path,cand)
s.cor = Corpus(DirSource(directory = s.dir,encoding = "ANSI"))
s.cor.cl = CleanCorpus(s.cor)
s.tdm = TermDocumentMatrix(s.cor.cl)
s.tdm = removeSparseTerms(s.tdm,0.7)
result = list(name = cand,tdm = s.tdm)
}
tdm = lapply(candidates,generateTDM,path = pathname)
tdm = lapply(candidates,generateTDM,path = pathname)
pathname = "\home\abhijit331/Text-Mining/"
pathname = "/home/abhijit331/Text-Mining/"
tdm = lapply(candidates,generateTDM,path = pathname)
library(tm)
library(dplyr)
options(stringsAsFactors = F)
candidates = c("Romney","Obama")
pathname = "/home/abhijit331/Text-Mining/"
# Clean the text
CleanCorpus = function(corpus)
{
corpus.tmp = tm_map(corpus,removePunctuation)
corpus.tm = tm_map(corpus.tmp,stripWhitespace)
corpus.tm = tm_map(corpus.tmp,tolower)
corpus.tm = tm_map(corpus.tmp,removeWords,stopwords("english"))
return(corpus.tm)
}
generateTDM = function(cand,path){
s.dir = paste(path,cand)
s.cor = Corpus(DirSource(directory = s.dir,encoding = "ANSI"))
s.cor.cl = CleanCorpus(s.cor)
s.tdm = TermDocumentMatrix(s.cor.cl)
s.tdm = removeSparseTerms(s.tdm,0.7)
result = list(name = cand,tdm = s.tdm)
}
tdm = lapply(candidates,generateTDM,path = pathname)
setwd("/home/abhijit331/Text-Mining")
pathname
paste(pathname,"Obama")
paste(pathname,"Obama","")
paste(pathname,"Obama",collapse = "")
paste(pathname,"Obama",collapse = "")
paste(pathname,"Obama",collapse ="")
paste(pathname,"Romney",collapse ="")
paste0(pathname,"Romney")
paste0(pathname,"Obama")
library(tm)
library(dplyr)
options(stringsAsFactors = F)
candidates = c("Romney","Obama")
pathname = "/home/abhijit331/Text-Mining/"
# Clean the text
CleanCorpus = function(corpus)
{
corpus.tmp = tm_map(corpus,removePunctuation)
corpus.tm = tm_map(corpus.tmp,stripWhitespace)
corpus.tm = tm_map(corpus.tmp,tolower)
corpus.tm = tm_map(corpus.tmp,removeWords,stopwords("english"))
return(corpus.tm)
}
generateTDM = function(cand,path){
s.dir = paste0(path,cand)
s.cor = Corpus(DirSource(directory = s.dir,encoding = "ANSI"))
s.cor.cl = CleanCorpus(s.cor)
s.tdm = TermDocumentMatrix(s.cor.cl)
s.tdm = removeSparseTerms(s.tdm,0.7)
result = list(name = cand,tdm = s.tdm)
}
tdm = lapply(candidates,generateTDM,path = pathname)
tdm = lapply(candidates,generateTDM,path = pathname)
candidates = c("Romney","Obama")
pathname = "/home/abhijit331/Text-Mining/"
# Clean the text
CleanCorpus = function(corpus)
{
corpus.tmp = tm_map(corpus,removePunctuation)
corpus.tm = tm_map(corpus.tmp,stripWhitespace)
corpus.tm = tm_map(corpus.tmp,tolower)
corpus.tm = tm_map(corpus.tmp,removeWords,stopwords("english"))
return(corpus.tm)
}
generateTDM = function(cand,path){
s.dir = paste0(path,cand)
s.cor = Corpus(DirSource(directory = s.dir,encoding = "UTF-8"))
s.cor.cl = CleanCorpus(s.cor)
s.tdm = TermDocumentMatrix(s.cor.cl)
s.tdm = removeSparseTerms(s.tdm,0.7)
result = list(name = cand,tdm = s.tdm)
}
tdm = lapply(candidates,generateTDM,path = pathname)
tdm
bindCandidatetoTDM = function(tdm)
{
s.mat = t(data.matrix(tdm[["tdm"]]))
s.df = as.data.frame(s.mat, stringsAsFactors = F)
s.df = cbind(s.df,rep(tdm[["name"]],nrow(s.df)))
colnames(s.df)[ncol(s.df)] = "targetcandidate"
return(s.df)
}
candTDM = lapply(tdm,bindCandidatetoTDM)
str(candTDM)
tdm.stack = do.call(rbind.fill,candTDM)
library(plyr)
library(plyr)
library(dplyr)
tdm.stack = do.call(rbind.fill,candTDM)
tdm.stack[is.na(tdm.stack)] = 0
head(tdm.stack)
nrow(tdm.stack)
ncol(tdm.stack)
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) = 0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
head(train.idx)
head(train.idx)
head(test.idx)
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
?knn
library(class)
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
train.idx
test.idx
length(test.idx)
knn.pred
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
# creating training and testing sample
train.idx = sample(nrow(tdm.stack),ceiling(nrow(tdm.stack) *0.7))
test.idx = (1:nrow(tdm.stack))[-train.idx]
# KNN model :
tdm.cand = tdm.stack[,"targetcandidate"]
tdm.stack.nl = tdm.stack[,!colnames(tdm.stack) %in% "targetcandidate"]
knn.pred = knn(tdm.stack.nl[train.idx,] , tdm.stack.nl[test.idx,],tdm.cand[train.idx])
conf.mat = table("Pred" = knn.pred,Actual = tdm.cand[test.idx])
conf.mat
sample(100,10)
sample(1,10)
